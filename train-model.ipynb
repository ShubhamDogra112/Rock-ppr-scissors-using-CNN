{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "et6mQHpbANIT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense  , Dropout , Conv2D , MaxPool2D , Flatten\n",
        "import numpy as np\n",
        "from keras.optimizers import Adam  , rmsprop"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Using TensorFlow backend.\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ITW2OLSfMEgm"
      },
      "source": [
        "## Creating Cnn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X25fq8SkAmcN",
        "colab_type": "code",
        "outputId": "2f2cf65f-f143-4de1-b1f8-08fbd24c68c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(64,(3,3),activation='relu',input_shape=(150,150,3)))\n",
        "model.add(MaxPool2D((2,2)))\n",
        "model.add(Conv2D(64,(3,3),activation='relu',))\n",
        "model.add(MaxPool2D((2,2)))\n",
        "model.add(Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(MaxPool2D((2,2)))\n",
        "model.add(Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(MaxPool2D((2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(3,activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 148, 148, 64)      1792      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 74, 74, 64)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 72, 72, 64)        36928     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 34, 34, 128)       73856     \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 17, 17, 128)       0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 15, 15, 128)       147584    \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 7, 7, 128)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 6272)              0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 6272)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 64)                401472    \n_________________________________________________________________\ndense_2 (Dense)              (None, 3)                 195       \n=================================================================\nTotal params: 661,827\nTrainable params: 661,827\nNon-trainable params: 0\n_________________________________________________________________\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrwD-lm1AwUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining test and train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qAo_xGNA2xi",
        "colab_type": "code",
        "outputId": "ba45213e-67c3-4a09-b229-b61d0c21e85e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from keras_preprocessing import image\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "training_dir = './train'\n",
        "validation_dir = \"./Test\"\n",
        "training_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    rotation_range = 40,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip =True,\n",
        "    fill_mode  = 'nearest'\n",
        "\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255\n",
        ")\n",
        "\n",
        "train_generator = training_datagen.flow_from_directory(\n",
        "    training_dir,\n",
        "    target_size = (150 , 150),\n",
        "    class_mode ='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size = (150 , 150),\n",
        "    class_mode ='categorical'\n",
        ")\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found 2140 images belonging to 3 classes.\nFound 360 images belonging to 3 classes.\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEnOHqp1Em39",
        "colab_type": "code",
        "outputId": "f5348233-7981-4dcc-881a-656003951506",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        }
      },
      "source": [
        "hist = model.fit(train_generator,epochs=25,validation_data = validation_generator,verbose = 1)\n",
        "\n",
        "model.save(\"rps.h6\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/25\n67/67 [==============================] - 130s 2s/step - loss: 1.1277 - accuracy: 0.4107 - val_loss: 0.7428 - val_accuracy: 0.8111\nEpoch 2/25\n67/67 [==============================] - 97s 1s/step - loss: 0.9576 - accuracy: 0.5430 - val_loss: 0.5039 - val_accuracy: 0.9250\nEpoch 3/25\n67/67 [==============================] - 95s 1s/step - loss: 0.7932 - accuracy: 0.6350 - val_loss: 0.5214 - val_accuracy: 0.9167\nEpoch 4/25\n67/67 [==============================] - 95s 1s/step - loss: 0.6447 - accuracy: 0.7299 - val_loss: 0.1025 - val_accuracy: 0.9583\nEpoch 5/25\n67/67 [==============================] - 95s 1s/step - loss: 0.5367 - accuracy: 0.7748 - val_loss: 0.0468 - val_accuracy: 0.9556\nEpoch 6/25\n67/67 [==============================] - 95s 1s/step - loss: 0.4578 - accuracy: 0.8215 - val_loss: 0.0016 - val_accuracy: 0.9333\nEpoch 7/25\n67/67 [==============================] - 95s 1s/step - loss: 0.4092 - accuracy: 0.8486 - val_loss: 0.0158 - val_accuracy: 0.9556\nEpoch 8/25\n67/67 [==============================] - 95s 1s/step - loss: 0.3540 - accuracy: 0.8612 - val_loss: 0.0940 - val_accuracy: 0.9722\nEpoch 9/25\n67/67 [==============================] - 87s 1s/step - loss: 0.3045 - accuracy: 0.8715 - val_loss: 0.0171 - val_accuracy: 0.9750\nEpoch 10/25\n67/67 [==============================] - 79s 1s/step - loss: 0.3039 - accuracy: 0.8813 - val_loss: 0.0038 - val_accuracy: 0.9556\nEpoch 11/25\n67/67 [==============================] - 97s 1s/step - loss: 0.2457 - accuracy: 0.9103 - val_loss: 0.4289 - val_accuracy: 0.9639\nEpoch 12/25\n67/67 [==============================] - 96s 1s/step - loss: 0.2783 - accuracy: 0.8972 - val_loss: 0.9183 - val_accuracy: 0.9556\nEpoch 13/25\n67/67 [==============================] - 90s 1s/step - loss: 0.2160 - accuracy: 0.9150 - val_loss: 0.1767 - val_accuracy: 0.9389\nEpoch 14/25\n67/67 [==============================] - 92s 1s/step - loss: 0.2000 - accuracy: 0.9318 - val_loss: 8.3119e-04 - val_accuracy: 0.9639\nEpoch 15/25\n67/67 [==============================] - 95s 1s/step - loss: 0.1966 - accuracy: 0.9243 - val_loss: 0.0245 - val_accuracy: 0.9583\nEpoch 16/25\n67/67 [==============================] - 97s 1s/step - loss: 0.1665 - accuracy: 0.9346 - val_loss: 8.0623e-04 - val_accuracy: 0.9667\nEpoch 17/25\n67/67 [==============================] - 100s 1s/step - loss: 0.1844 - accuracy: 0.9379 - val_loss: 0.1522 - val_accuracy: 0.9444\nEpoch 18/25\n67/67 [==============================] - 96s 1s/step - loss: 0.1750 - accuracy: 0.9463 - val_loss: 0.0021 - val_accuracy: 0.9722\nEpoch 19/25\n67/67 [==============================] - 103s 2s/step - loss: 0.1488 - accuracy: 0.9528 - val_loss: 0.1771 - val_accuracy: 0.9694\nEpoch 20/25\n67/67 [==============================] - 103s 2s/step - loss: 0.1400 - accuracy: 0.9491 - val_loss: 0.6408 - val_accuracy: 0.9722\nEpoch 21/25\n67/67 [==============================] - 98s 1s/step - loss: 0.1435 - accuracy: 0.9467 - val_loss: 0.0028 - val_accuracy: 0.9833\nEpoch 22/25\n67/67 [==============================] - 101s 2s/step - loss: 0.1292 - accuracy: 0.9556 - val_loss: 6.2804e-05 - val_accuracy: 0.9750\nEpoch 23/25\n67/67 [==============================] - 91s 1s/step - loss: 0.1293 - accuracy: 0.9528 - val_loss: 1.1569 - val_accuracy: 0.9528\nEpoch 24/25\n67/67 [==============================] - 89s 1s/step - loss: 0.1185 - accuracy: 0.9593 - val_loss: 3.4051e-04 - val_accuracy: 0.9806\nEpoch 25/25\n67/67 [==============================] - 90s 1s/step - loss: 0.1077 - accuracy: 0.9612 - val_loss: 5.1090e-05 - val_accuracy: 0.9750\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izFjGOnSK85p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras_preprocessing import image"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX5dDveDdZXi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f1740a5e-f547-4308-bf32-ad5e6c33e020"
      },
      "source": [
        "rps = load_model(\"rps.h6\")\n",
        "# img = image.load_img('./rock 19.jpg' , target_size=(150,150))\n",
        "# img = image.load_img('./paper 85.jpg' , target_size=(150,150))\n",
        "img = image.load_img('./Test/paper/paper 308.jpg' , target_size=(150,150))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "img = image.img_to_array(img)\n",
        "img = np.expand_dims(img , axis=0)\n",
        "\n",
        "pred = rps.predict(img)\n",
        "label = np.argmax(pred[0])\n",
        "print(label)\n",
        "\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "0\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKBtv3S_mQKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "rps.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python37464bit407e9aec42c34a81b2e0325190436580",
      "display_name": "Python 3.7.4 64-bit"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}